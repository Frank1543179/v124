---
title: Finite-Memory Near-Optimal Learning for Markov Decision Processes with Long-Run
  Average Reward
abstract: We consider learning policies online in Markov decision processes with the
  long-run average reward (a.k.a. mean payoff). To ensure implementability of the
  policies, we focus on policies with finite memory. Firstly, we show that near optimality
  can be achieved almost surely, using an unintuitive gadget we call forgetfulness.
  Secondly, we extend the approach to a setting with partial knowledge of the system
  topology, introducing two optimality measures and providing near-optimal algorithms
  also for these cases.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: kretinsky20a
month: 0
tex_title: Finite-Memory Near-Optimal Learning for Markov Decision Processes with
  Long-Run Average Reward
firstpage: 1149
lastpage: 1158
page: 1149-1158
order: 1149
cycles: false
bibtex_author: Kretinsky, Jan and Michel, Fabian and Michel, Lukas and Perez, Guillermo
author:
- given: Jan
  family: Kretinsky
- given: Fabian
  family: Michel
- given: Lukas
  family: Michel
- given: Guillermo
  family: Perez
date: 2020-08-27
address: 
container-title: Proceedings of the 36th Conference on Uncertainty in Artificial Intelligence
  (UAI)
volume: '124'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 8
  - 27
pdf: http://proceedings.mlr.press/v124/kretinsky20a/kretinsky20a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v124/kretinsky20a/kretinsky20a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
