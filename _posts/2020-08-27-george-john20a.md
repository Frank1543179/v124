---
title: Verifying Individual Fairness in Machine Learning Models
abstract: "{We consider the problem of whether a given decision model, working with
  structured data, has individual fairness. Following the work of Dwork, a model is
  individually biased (or unfair) if there is a pair of valid inputs which are close
  to each other (according to an appropriate metric) but are treated differently by
  the model (different class label, or large difference in output), and it is unbiased
  (or fair) if no such pair exists. Our objective is to construct verifiers for proving
  individual fairness of a given model, and we do so by considering appropriate relaxations
  of the problem. We construct verifiers which are sound but not complete for linear
  classifiers, and kernelized polynomial/radial basis function classifiers. We also
  report the experimental results of evaluating our proposed algorithms on publicly
  available datasets.}"
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: george-john20a
month: 0
tex_title: "{Verifying Individual Fairness in Machine Learning Models}"
firstpage: 749
lastpage: 758
page: 749-758
order: 749
cycles: false
bibtex_author: George John, Philips and Vijaykeerthy, Deepak and Saha, Diptikalyan
author:
- given: Philips
  family: George John
- given: Deepak
  family: Vijaykeerthy
- given: Diptikalyan
  family: Saha
date: 2020-08-27
address: 
container-title: "{Proceedings of the 36th Conference on Uncertainty in Artificial
  Intelligence (UAI)}"
volume: '124'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 8
  - 27
pdf: http://proceedings.mlr.press/v124/george-john20a/george-john20a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v124/george-john20a/george-john20a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
