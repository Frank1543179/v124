---
title: No-regret Exploration in Contextual Reinforcement Learning
abstract: "{We consider the recently proposed reinforcement learning (RL) framework
  of Contextual Markov Decision Processes (CMDP), where the agent interacts with a
  (potentially adversarial) sequence of episodic tabular MDPs. In addition, a context
  vector determining the MDP parameters is available to the agent at the start of
  each episode, thereby allowing it to learn a context-dependent near-optimal policy.
  In this paper, we propose a no-regret online RL algorithm in the setting where the
  MDP parameters are obtained from the context using generalized linear mappings (GLMs).
  We propose and analyze optimistic and randomized exploration methods which make
  (time and space) efficient online updates. The GLM based model subsumes previous
  work in this area and also improves previous known bounds in the special case where
  the contextual mapping is linear. In addition, we demonstrate a generic template
  to derive confidence sets using an online learning oracle and give a lower bound
  for the setting.}"
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: modi20a
month: 0
tex_title: "{No-regret Exploration in Contextual Reinforcement Learning}"
firstpage: 829
lastpage: 838
page: 829-838
order: 829
cycles: false
bibtex_author: Modi, Aditya and Tewari, Ambuj
author:
- given: Aditya
  family: Modi
- given: Ambuj
  family: Tewari
date: 2020-08-27
address: 
container-title: "{Proceedings of the 36th Conference on Uncertainty in Artificial
  Intelligence (UAI)}"
volume: '124'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 8
  - 27
pdf: http://proceedings.mlr.press/v124/modi20a/modi20a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v124/modi20a/modi20a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
